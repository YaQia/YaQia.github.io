---
outline: deep
---
# 基础概念解析（主要涉及不常见概念）

## 机器学习问题分类

### 离线学习

#### 监督学习

在给定输入特征的情况下预测标签。根据标签个数有限或无限区分为**分类问题**和**回归问题**。

##### 回归问题

确定一个输入特征到输出标签的函数关系，输出标签的值域是连续的而非离散的。

##### 分类问题

与回归问题的输出标签相反，标签值域是离散的。模型输出不再是标签，而是每个标签类别的概率/收益。

##### 标记问题

预测互不排斥的类别的问题称为**多标签分类**。

:::info
例如，一张图片中不光有一个待识别物体，图片中存在多个类别的物体，输出应该包含所有在图中的物体的标签
:::

##### 搜索算法

标签类别互不排斥的同时，输出的结果集需要考虑顺序（以“重要度”排序）。

##### 推荐系统

推荐系统会为“给定用户和物品”的匹配性打分，这个“分数”可能是估计的评级或购买的概率。

##### 序列学习

上述回归问题和分类问题都具有**固定大小输入和固定大小输出**。如果输入是连续的，则模型需要拥有“记忆”能力。

:::info
典型模型：seq2seq
:::

#### 无监督学习

模型无法提供大规模数据集，无法让每个样本特征都有相应的标签值。数据中不含“目标”的机器学习问题被称为无监督学习。

例如：

- 聚类（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类呢？

- 主成分分析（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。
另一个例子：在欧几里得空间中是否存在一种（任意结构的）对象的表示，使其符号属性能够很好地匹配?
这可以用来描述实体及其关系，例如“罗马” - “意大利” + “法国” = “巴黎”。

- 因果关系（causality）和概率图模型（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？

- 生成对抗性网络（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。

### 强化学习/在线学习

引入环境，考虑的不再是“预测模型”，而是一个“智能体”(agent)。通过（观察，动作，奖励）三元组完成一轮循环。

- 观察(Observation)：通过环境状态返回的结果
- 动作(Action)：有限的集合，f(O, A) -> O'
- 奖励(Reward)：根据动作和环境信息得出当前的奖励

![强化学习与环境的互相作用](https://zh.d2l.ai/_images/rl-environment.svg)

## 什么是表示学习(representation learning)？

表示学习是机器学习的一类，重点研究如何**自动找到**合适的数据表示方式。深度学习是通过学习多层次的转换进行**多层表示学习**。

## 什么是端到端训练？

区别于传统机器学习方法，深度学习方法的显著共同点是使用端到端训练：

**与其基于单独调整的组件组装整个系统，不如直接构建整个系统，然后联合调整它们的性能。**

:::info
例如：

在传统方法中，计算机视觉领域的研究习惯于拆分特征工程和机器学习模型，先用Canny边缘检测和SIFT特征提取将图像特征映射到特征向量，再用这些人工提取的特征向量去训练神经网络。

实际上，人工特征工程能完成的事情很少。深度学习将这些特征提取器调整为自动的滤波器后，网络产生了更高的精度。
:::

## 参考文献

[d2l引言](https://zh.d2l.ai/chapter_introduction/index.html)
